from . import *
from utils.util import google_search_scrape, extract_content
from modules.db import UserData

class State(MessagesState):
    is_search: str
    is_personal: str
    is_preference: str
    
class ChatbotAgent:
    def __init__(self):
        self.LIMIT_LENGTH = 12
        self.SEARCH_RETRY_COUNT = 5
        self.SEARCH_RESULT_COUNT = 4
        self.SEARCH_MINIMUM_RESULT = 1
        self.system_prompt = prompt_config.system_message
        self.search_keyword = ''
        self.llm = ChatOpenAI(model="gpt-4o")
        self.config = {"configurable": {"thread_id": "default",
                                        "user_id": "default"}}
        self.user_data = UserData()
        self._build_graph()
        
    async def get_response(self,
                           question: str) -> str:
        question = HumanMessage(content=question)
        return self._call_graph([question])["messages"][-1].content
    
    def set_config(self,
                   user_id:str):
        self.config = {"configurable": {"thread_id": user_id, # ì–´ì°¨í”¼ ì¹´í†¡ì€ ì±„íŒ…ì°½ ì—¬ëŸ¬ê°œë¥¼ ë„ìš¸ìˆ˜ì—†ê¸°ì—, thread ê°’ë„ user_idë¡œ ê³ ì •
                                        "user_id": user_id}}
        
    def _build_graph(self):
        """
            Des:
                ê·¸ë˜í”„ ìƒì„±í•¨ìˆ˜
        """
        builder = StateGraph(State)
        builder.add_node("_node_initialize", self._node_initialize)
        builder.add_node("_node_decide_personal", self._node_decide_personal)
        builder.add_node("_node_decide_preference", self._node_decide_preference)
        builder.add_node("_node_decide_search", self._node_decide_search)
        builder.add_node("_node_write_memory", self._node_write_memory)
        builder.add_node("_node_answer", self._node_answer)
        builder.add_node("_node_optimize_memory", self._node_optimize_memory)
        builder.add_edge(START, "_node_initialize")
        builder.add_edge("_node_initialize", "_node_decide_personal")
        builder.add_edge("_node_initialize", "_node_decide_preference")
        builder.add_edge("_node_initialize", "_node_decide_search")
        builder.add_edge(["_node_decide_personal", "_node_decide_preference", "_node_decide_search"], "_node_write_memory")
        builder.add_edge("_node_write_memory", "_node_answer")
        builder.add_edge("_node_answer", "_node_optimize_memory")
        builder.add_edge("_node_optimize_memory", END)
        ShortTermMemory = MemorySaver()
        LongTermMemory = InMemoryStore()
        self.graph = builder.compile(checkpointer=ShortTermMemory,
                                     store=LongTermMemory)
        print(f"{GREEN}[agent.py] ê·¸ë˜í”„ ë¹Œë“œ ì™„ë£Œ{RESET}")
        
    @trace_function(enable_print=False, only_func_name=True)
    def _node_initialize(self, 
                         state: State,
                         config: RunnableConfig, 
                         store: BaseStore):
        """
            Des:
                ì´ˆê¸°í™” í•¨ìˆ˜
                    - ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
                        - ì¼€ì´ìŠ¤ 1) ì‚¬ìš©ìê°€ ì±„íŒ… ì²˜ìŒ ì‹œì‘ -> set_config -> DBì— ì •ë³´ì—†ìœ¼ë‹ˆê¹Œ elseë¡œ ê°€ì„œ ì¢…ë£Œ
                        - ì¼€ì´ìŠ¤ 2) ì‚¬ìš©ìê°€ ì±„íŒ…ì„ 'ìƒˆë¡œìš´ ëŒ€í™”'ë¡œ ì‹œì‘í•¨ -> ê·¸ë˜í”„ ìƒˆë¡œ ë¹Œë“œ -> ë¡±í…€ ì´ˆê¸°í™” -> set_config -> ì‚¬ìš©ì ì •ë³´ê°€ ìˆìœ¼ë‹ˆê¹Œ ë°ì´í„° ì‚½ì…
                        - ì¼€ì´ìŠ¤ 3) ì‚¬ìš©ìê°€ ì±„íŒ…ì„ í–ˆì—ˆëŠ”ë° ë‚´ê°€ ì„œë²„ ë‹¤ì‹œí‚´ -> ê·¸ë˜í”„ ìƒˆë¡œ ë¹Œë“œ -> ë¡±í…€ ì´ˆê¸°í™” -> set_config -> ì‚¬ìš©ì ì •ë³´ê°€ ìˆìœ¼ë‹ˆê¹Œ ë°ì´í„° ì‚½ì…
                    - ì‚¬ìš©ì ì •ë³´ ì´ˆê¸°í™”
                    - ì‚¬ìš©ì ìš”ì²­ë©”ì‹œì§€ ì·¨í•©
        """
        user_id = config["configurable"]["user_id"]
        namespace = ("memories", user_id)
        user_info = self.user_data.process_request(user_id)
        if user_info:
            print(f"{YELLOW}[agent.py] ë°ì´í„°ë² ì´ìŠ¤ì— ì´ì „ ì‚¬ìš©ì ì •ë³´ê°€ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜í”„ë‚´ì— ë°ì´í„°ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤.{RESET}")
            store.put(namespace=namespace, 
                      key="personal_info", 
                      value={"memory":user_info[1]})
            store.put(namespace=namespace,  
                      key="personal_preference", 
                      value={"memory":user_info[2]})
        else:
            print(f"{YELLOW}[agent.py] ë°ì´í„°ë² ì´ìŠ¤ì— ì´ì „ ì‚¬ìš©ì ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.{RESET}")
            
        # ì‚¬ìš©ì ìš”ì²­ë©”ì‹œì§€ë§Œ ì·¨í•©í•´ì„œ ì •ë¦¬ (ë¼ìš°íŒ… ë“±ì—ì„œ ì‚¬ìš©)
        self.previous_human_messages = [i.content for i in state["messages"] if isinstance(i, HumanMessage)]
        self.previous_human_messages_query = ''
        for idx, message in enumerate(self.previous_human_messages, start=1):
            if idx != len(self.previous_human_messages):
                self.previous_human_messages_query += f"{idx}ë²ˆì§¸ ìš”ì²­ ë©”ì‹œì§€ : {message}\n"
            else:
                self.previous_human_messages_query += f"[í˜„ì¬ ìš”ì²­ ë©”ì‹œì§€] : {message}\n"
        print(f"{RED}ìš”ì²­ ë©”ì‹œì§€ ì·¨í•©í•œê±° ë©”ì‹œì§€ : {self.previous_human_messages_query}{RESET}")
        
    @trace_function(enable_print=False, only_func_name=True)
    def _node_decide_personal(self, 
                              state: State):
        """
            Des:
                ì‚¬ìš©ì ìš”ì²­ì— ê°œì¸ì •ë³´ ì—¬ë¶€ê°€ ìˆëŠ”ì§€ íŒë‹¨í•˜ëŠ” ë…¸ë“œ
        """
        prompt = [SystemMessage(content=prompt_config.decide_personal_prompt)] + [HumanMessage(content=self.previous_human_messages_query)]
        return {"is_personal":[self.llm.invoke(prompt)][0].content.upper()}

    @trace_function(enable_print=False, only_func_name=True)
    def _node_decide_preference(self, 
                                state: State):
        """
            Des:
                ì‚¬ìš©ì ìš”ì²­ì— ë‹µë³€ ì„ í˜¸ë„ ì—¬ë¶€ê°€ ìˆëŠ”ì§€ íŒë‹¨í•˜ëŠ” ë…¸ë“œ
        """
        prompt = [SystemMessage(content=prompt_config.decide_preference_prompt)] + [HumanMessage(content=self.previous_human_messages_query)]
        return {"is_preference":[self.llm.invoke(prompt)][0].content.upper()}

    @trace_function(enable_print=False, only_func_name=True)
    def _node_decide_search(self, 
                            state: State):
        """
            Des:
                ì‚¬ìš©ì ìš”ì²­ì— ê²€ìƒ‰ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” ë…¸ë“œ
        """
        prompt = [SystemMessage(content=prompt_config.decide_search_prompt)] + [HumanMessage(content=self.previous_human_messages_query)]
        return {"is_search":[self.llm.invoke(prompt)][0].content.upper()}

    @trace_function(enable_print=False, only_func_name=True)
    def _node_write_memory(self, 
                           state: State, 
                           config: RunnableConfig, 
                           store: BaseStore):
        """
            Des:
                ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì¸ì‹í•˜ê³ , ê°œì¸ì •ë³´/ì„ í˜¸ë„/ê²€ìƒ‰ê²°ê³¼ ë“±ì„ ì €ì¥í•˜ëŠ” ë…¸ë“œ
        """
        user_id = config["configurable"]["user_id"]
        namespace = ("memories", user_id)
        if state.get("is_personal") == "YES":
            personal_memory = self._get_memory(namespace=namespace, 
                                               key="personal_info", 
                                               store=store)
            system_message = prompt_config.create_memory_prompt.format(memory=personal_memory)
            memory_prompt = [SystemMessage(content=system_message)] + [HumanMessage(content=self.previous_human_messages_query)]
            result = self.llm.invoke(memory_prompt).content
            store.put(namespace=namespace, 
                      key="personal_info", 
                      value={"memory":result})    
            self.user_data.update_user_info(user_id, "personal_info", result)
        if state.get("is_preference") == "YES":
            preference_memory = self._get_memory(namespace=namespace, 
                                                 key="personal_preference", 
                                                 store=store)
            system_message = prompt_config.create_preference_prompt.format(preference=preference_memory)
            preference_prompt = [SystemMessage(content=system_message)] + [HumanMessage(content=self.previous_human_messages_query)]
            result = self.llm.invoke(preference_prompt).content
            store.put(namespace=namespace, 
                      key="personal_preference", 
                      value={"memory":result})
            self.user_data.update_user_info(user_id, "personal_preference", result)

        if state.get("is_search") == "YES":
            main_context, suffix_context = self._web_search()
            store.put(namespace=namespace, 
                      key="main_context", 
                      value={"memory":main_context})
            store.put(namespace=namespace, 
                      key="suffix_context", 
                      value={"memory":suffix_context})
        
    @trace_function(enable_print=False, only_func_name=True)
    def _node_answer(self, 
                     state: State, 
                    config: RunnableConfig,
                    store: BaseStore):
        """
            Des:
                ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì¸ì‹í•˜ê³ , ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë…¸ë“œ
        """
        user_id = config["configurable"]["user_id"]
        namespace = ("memories", user_id)
        personal_memory = self._get_memory(namespace=namespace, 
                                           key="personal_info", 
                                           store=store)
        personal_preference = self._get_memory(namespace=namespace, 
                                               key="personal_preference", 
                                               store=store)

        if state.get("is_search") == "YES":
            main_context = self._get_memory(namespace=namespace, 
                                            key="main_context", 
                                            store=store)
            suffix_context = self._get_memory(namespace=namespace, 
                                              key="suffix_context", 
                                              store=store)
            system_message = prompt_config.answer_prompt.format(memory=personal_memory,
                                                                preference=personal_preference)
            user_prompt = prompt_config.answer_with_context.format(context=main_context,
                                                                   query=state['messages'][-1].content)
            prompt = [SystemMessage(content=self.system_prompt+system_message)] + [HumanMessage(content=user_prompt)]
            print(f"{BLUE}Answer with Search prompt : {prompt[0].content}{RESET}")
            response = self.llm.invoke(prompt).content
            return {"messages": AIMessage(content=self._postprocess(response) + "\n" + suffix_context)}
        else:    
            system_message = prompt_config.answer_prompt.format(memory=personal_memory,
                                                                preference=personal_preference)
            prompt = [SystemMessage(content=self.system_prompt+system_message)] + state["messages"]
            print(f"{BLUE}Answer prompt : {prompt[0].content}{RESET}")
            response = self.llm.invoke(prompt).content
            return {"messages": AIMessage(content=self._postprocess(response))}

    @trace_function(enable_print=False, only_func_name=True)
    def _node_optimize_memory(self, 
                              state: State):
        """
            Des:
                ë©”ëª¨ë¦¬ ìµœì í™” í•¨ìˆ˜
        """
        if len(state["messages"]) > self.LIMIT_LENGTH:
            delete_messages = [RemoveMessage(id=m.id) for m in state["messages"][:self.LIMIT_LENGTH//2]]
            return {"messages": delete_messages}
        else:
            return {"messages": state["messages"]}

    @trace_function(enable_print=False, only_func_name=False)
    def _web_search(self):
        prompt = prompt_config.generate_search_keyword.format(query=self.previous_human_messages_query,
                                                              previous_search_keyword=self.search_keyword)
        self.search_keyword = self.llm.invoke(prompt).content
        for _ in range(self.SEARCH_RETRY_COUNT):
            results = google_search_scrape(self.search_keyword, num_results=self.SEARCH_RESULT_COUNT)
            if len(results) >= self.SEARCH_MINIMUM_RESULT:
                break
        print(f"{RED}ê²€ìƒ‰ì–´ : {self.search_keyword}\nê²€ìƒ‰ê²°ê³¼ : {len(results)}\n{RESET}")
        main_context = ''
        suffix_context = ''
        for idx, result in enumerate(results):
            link = result.get("link")
            try:
                desc, detailed_content = extract_content(link)
            except:
                pass
            try:
                if "Enable JavaScript and cookies" in detailed_content: # TODO ë™ì í˜ì´ì§€ ì²˜ë¦¬ë°©ì‹ í•„ìš”
                    continue
            except:
                continue
            main_context += f"ì œëª© : {result.get('title')}\në§í¬ : {link}\nì„¤ëª… : {desc}\në‚´ìš© : {detailed_content}\n\n"    
            suffix_context += f"""
ğŸ“Œ ì°¸ê³ ë‚´ìš© [{idx+1}]
ì œëª© : {result.get('title')}
ë§í¬ : {link}
ì„¤ëª… : {desc}
"""
        return main_context, suffix_context
    
    def _get_memory(self,
                    namespace, 
                    key,
                    store:BaseStore):
        """
            Des:
                í˜„ì¬ ì €ì¥ëœ ì‚¬ìš©ì ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
        """
        existing_memory = store.get(namespace=namespace,
                                    key=key)
        return existing_memory.value.get('memory') if existing_memory else ""

    def _call_graph(self, 
                    messages):
        """
            Des:
                ê·¸ë˜í”„ í˜¸ì¶œ í•¨ìˆ˜
        """
        return self.graph.invoke({"messages": messages}, config=self.config)
    
    def _postprocess(self,
                     result:str):
        result = result.replace("**", "").replace("*", "").replace("_", "")
        return result